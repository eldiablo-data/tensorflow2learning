{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e3a34b-aa0a-4ef9-989e-4e6270768382",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Simple Tensorflow Demo for MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7f6f5-2493-4621-b6d7-ada926a86fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d5888-e6b4-4852-b338-475cd9d3cefe",
   "metadata": {},
   "source": [
    "## Loading MNIST data\n",
    "MNIST dataset is already available within tensorflow package. The numbers are represented as 28x28 pixels stored as array. The pixels have value ranging from 0 to 255 which represents the gray scale from white to black respectively. The load() function returns a tuple of training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8b057-0bc2-4b03-9190-8d91d4d57cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test)= mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d2b9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train_scaled = x_train/255\n",
    "x_test_scaled = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44d46f-e134-4600-b95d-76e55b796eaa",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc78c65-e2f8-4c06-b9c6-85ad6bafb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b427599-57f7-4ade-a699-7a8d3b8fc685",
   "metadata": {},
   "source": [
    "The above model is a Sequential model. Here, each layer gets input from the previous layer and passed output to next layer. As alternative to Sequential model, the Functional API of Keras allows users to define more complex graph or layers where a layer can get input from more than one layer and pass outputs to multiple layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edb1c0-9989-46b0-be25-3a1158b4c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb32a8-a1e0-4a82-bc73-9e663d58f9ea",
   "metadata": {},
   "source": [
    "Usually images are flattened into a vector to represent each input image as a row of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91bd4e5-0c31-4210-8052-870b8322378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3002bd3-1fe4-4391-a3a9-396686d573c1",
   "metadata": {},
   "source": [
    "Dense layer is a regular densely-connected NN layer. The number of units is a hyper-parameter selected by experience. \n",
    "The output of a dense layer is calculated by `output = activation(dot(input, kernel) + bias)`. Here the ReLU or Rectified Linear Unit activation function is used. ReLU is half rectified function and it returns 0 for all negative inputs and for positive inputs it increases monotonically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b5812-2db4-47b1-8526-7b8c430c2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c39fd4-ce8d-47ba-9c33-595b332e2443",
   "metadata": {},
   "source": [
    "The dropout layer sets input units to 0 with the given rate. This is used to prevent overfitting. The shape can also be modified into a 1D tensor mask. And seed values can also be fixed. The dropout is active only when `training=True`. During inference, it is not used. During `model.fit()` training is True by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ccb161-724d-4f94-88a1-950c4bd5867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10,'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9f708-ce0a-4163-ad99-7acb0157e999",
   "metadata": {},
   "source": [
    "Softmax converts a vector of values into a probablity distribution. Usually it is used in output layers as it can be used to interpret probablity distributions. Here 10 is used as we have 0-9 as the labels. \n",
    "\n",
    "## Compile the Model\n",
    "\n",
    "During this step, the configurations of the model are assigned. Optimizers are described in detail on later sections. In this example, `adam`optimizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5468e10-0604-41b6-9df0-727bc84e4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442dca7a-5c41-465a-ae93-f62c9cb91a00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`sparse_categorial_crossentropy` function used here is a loss function that is useful when the output prediction is a sparse array. In this case, the one-hot encoding \n",
    "produces 1 for the right integer and 0 for all other indices. The `sparse_categorial_crossentropy` function only computes the loss for the k<sup>th</sup> index and ignores the rest.\n",
    "The cross entrophy loss for the rest of the positions would anyways be 0 and just summing up 0s is redundant. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786eb2d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x=x_train_scaled,y=y_train, validation_data=(x_test_scaled,y_test),epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
